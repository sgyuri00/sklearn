{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3manLlDGcTX"
      },
      "source": [
        "### Neural networks - image classification on cifar dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L8VmygirGcTZ"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0kua5PzGcTf"
      },
      "outputs": [],
      "source": [
        "# Load the cifar10 dataset\n",
        "# Use the load_data function (Check the function description what kind of output to expect.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W3FCsGsGcTl"
      },
      "outputs": [],
      "source": [
        "# Normalize pixel values to be between 0 and 1\n",
        "# What is the number of the possible pixel values?\n",
        "# Divide both the train_images and the test_images by that number\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOG_2JiGcTo"
      },
      "source": [
        "* Let's check our train images.\n",
        "* Find out how to create subplots.\n",
        "* E.g. you can study this website: w3schools.com/python/matplotlib_subplots.asp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRFpnCgLGcT8"
      },
      "outputs": [],
      "source": [
        "# There are 10 categories of the images:\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# We will check the first 25 images of the training dataset\n",
        "\n",
        "# Create a figure with some convinient size (e.g. 8x8)\n",
        "# Create a for loop with 25 iterations AND create subplots(5 rows and 5 cols)\n",
        "# In each subplot show the next train image (HINT: use the 'imshow' function)\n",
        "# Use x and yticks to not to show the default ticks\n",
        "# Put xlabel to the figures, use the class_names list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Check how to use 'grid', and try out different settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFnZkljxGcT-"
      },
      "source": [
        "* Let's train a convolutional neural network!\n",
        "* We will have sequential layers (read about them here: https://keras.io/guides/sequential_model/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4BJ_ELkGcUA",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create a basic sequential model: model\n",
        "# models package is already imported from tensorflow.keras, use the Sequential() function of this package\n",
        "\n",
        "\n",
        "# Now, we will add several layers to the model:\n",
        "\n",
        "# Add a Conv2D layer to the model\n",
        "# Use 32 filters\n",
        "# USe 3x3 kernel size\n",
        "# Use 'relu' activation function\n",
        "# Use input_shape=(32, 32, 3) (32rows, 32cols and 3 channels(RGB))\n",
        "\n",
        "\n",
        "# Add a MaxPooling2D layer with pool size 2x2\n",
        "\n",
        "\n",
        "# Add a Conv2D layer with the following parameters:\n",
        "# 64 filters, 3x3 kernel, 'relu' activation\n",
        "\n",
        "\n",
        "# Add a MaxPooling2D layer with pool size 2x2\n",
        "\n",
        "\n",
        "# Add a Conv2D layer with the following parameters:\n",
        "# 64 filters, 3x3 kernel, 'relu' activation\n",
        "\n",
        "\n",
        "# Flatten your layer (for gaining the final output, we need a column vector)\n",
        "# Use the Flatten() function\n",
        "\n",
        "\n",
        "# Add two Dense layers\n",
        "# 1. with dimension 64 and activation function 'relu'\n",
        "# 2. with dimension 10 and activation function 'softmax'\n",
        "\n",
        "\n",
        "# Check the final model with the summary() function\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu5K4SQcGcUD"
      },
      "source": [
        "* So finally we created our model\n",
        "* The next step is to compile it - configure the learning process of the model\n",
        "* Here, you can read about the model compilation process: https://www.tutorialspoint.com/keras/keras_model_compilation.htm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvSiPrZYGcUF"
      },
      "outputs": [],
      "source": [
        "# Compile the created model with the 'compile' function\n",
        "# Set the parameters to 'adam', 'sparse_categorical_crossentropy', 'accuracy'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3xuJTwFGcUG"
      },
      "source": [
        "* Next, we fit the model using our training data\n",
        "* (This will take some time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvGTrUeDGcUI"
      },
      "outputs": [],
      "source": [
        "# Fit the model using the 'fit' function\n",
        "# Specify the x, y, epoch, and validation_data parameters\n",
        "# Use 5 epochs (more will take too much time)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbMScnJlGcUJ"
      },
      "source": [
        "* Now, let's plot the result - the accuracy of the fitted model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbUHl8wbGcUL"
      },
      "outputs": [],
      "source": [
        "# Check the fitted model (history) with the history function (HINT: print(history.history))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_SAjZP9GcUM"
      },
      "outputs": [],
      "source": [
        "# Plot the 'accuracy' of the fitted model (this is the accuracy on the training set)\n",
        "\n",
        "\n",
        "# Plot the 'val_accuracy' of the fitted model (this is the accuracy on the test (validation) set)\n",
        "\n",
        "\n",
        "# Label the axes: 'Epoch' and 'Accuracy'\n",
        "\n",
        "\n",
        "\n",
        "# Limit the values of the y axis to the interval [0.5, 1]\n",
        "\n",
        "\n",
        "# Use the legend function to give description to the figure ('accuracy','val_accuracy')\n",
        "# Set the location of the legend to 'lower right'\n",
        "\n",
        "\n",
        "# Show the plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aWkshB_GcUO"
      },
      "source": [
        "* Evaluate the model using the test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70BSOaz4GcUP"
      },
      "outputs": [],
      "source": [
        "# Use the 'evaluate' function to evaluate the model (not the history!)\n",
        "# I recommend to set the 'verbose' parameter to 2 (you can check it for 0 or 1)\n",
        "\n",
        "\n",
        "# Print the test accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW9VGviLGcUQ"
      },
      "source": [
        "* Save the model in h5 format\n",
        "* Next time, you won't have to train the model again\n",
        "* You can just load the model\n",
        "* Saves lots of time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12OycdcLGcUS"
      },
      "outputs": [],
      "source": [
        "# Save your model with the 'save' function, call it 'my_model.h5'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqp1XVCUGcUT"
      },
      "source": [
        "* And finally, we test the model \n",
        "* Interprate the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDc3W_92GcUV"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('my_model.h5')\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "import numpy as np\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array, true_label[i][0], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    if predicted_label == true_label:\n",
        "        color = 'blue'\n",
        "    else:\n",
        "        color = 'red'\n",
        "\n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "    predictions_array, true_label = predictions_array, true_label[i][0]\n",
        "    plt.grid(False)\n",
        "    plt.xticks(range(10))\n",
        "    plt.yticks([])\n",
        "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "    plt.ylim([0, 1])\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "    thisplot[predicted_label].set_color('red')\n",
        "    thisplot[true_label].set_color('blue')\n",
        "\n",
        "i = 1\n",
        "#############\n",
        "predictions = model.predict(test_images[i:i+1])\n",
        "#############\n",
        "print(predictions)\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[0], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[0],  test_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eBjrtVZGcUW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "10.pactice.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
